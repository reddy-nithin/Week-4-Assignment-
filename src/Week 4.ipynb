{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "view-in-github",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "OpenFDA RAG demo notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7a2ae7b1",
      "metadata": {
        "id": "7a2ae7b1"
      },
      "source": [
        "# CS 5588 — Week 3 Hands-On  \n",
        "## Building a RAG Product Prototype (openFDA API)\n",
        "\n",
        "**Goal (today):** Build a *working product prototype* that answers user questions from openFDA drug labeling records (text fields) with **evidence citations**.\n",
        "\n",
        "**What you’ll leave with:**\n",
        "- A project-ready RAG pipeline (API fetch → indexing → retrieval → grounded answer)\n",
        "- A short **Product Brief** inside the notebook (persona, problem, value, success metrics)\n",
        "- A small **demo loop** you can show to stakeholders (prompt → answer + citations)\n",
        "\n",
        "> This hands-on is application-first: prioritize a realistic use case and a clean demo.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d25710df",
      "metadata": {
        "id": "d25710df"
      },
      "source": [
        "## 0) Product Brief (Fill in — REQUIRED for Week 3)\n",
        "\n",
        "* **Team / Name:** Salman Mirza, Amy Ngo, and Nithin Songala\n",
        "* **Project name (working title):** Drug Label Evidence Assistant (openFDA)\n",
        "\n",
        "### 0.1 Target user persona\n",
        "\n",
        "* **Who will use this?** Pharmacist, clinician, or regulatory analyst who needs quick answers from official drug labeling.\n",
        "* **Context + pain point:** They don’t have time to scan long label sections manually, and they need answers that are **trustworthy** and **cited** for clinical or compliance decisions.\n",
        "\n",
        "### 0.2 Problem statement (1–2 sentences)\n",
        "\n",
        "* Stakeholders need fast, accurate answers from drug labeling text, but the information is spread across long SPL sections. This product supports evidence-backed decision-making by retrieving the right label sections and producing grounded answers with citations.\n",
        "\n",
        "### 0.3 Value proposition (1 sentence)\n",
        "\n",
        "* Provides **faster time-to-answer** with **higher trust** by returning an evidence pack (label sections) and a **citation-enforced grounded answer**, refusing when evidence is missing.\n",
        "\n",
        "### 0.4 Success metrics (pick 2–3)\n",
        "\n",
        "* **Time-to-answer:** average < 30 seconds per stakeholder question.\n",
        "* **Citation coverage:** ≥ 2 citations per answer and includes required must-cite items for Task 1–2.\n",
        "* **Refusal accuracy:** Task 3 returns “Not enough evidence in the retrieved context.” when the labels don’t contain the requested info."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cf340d90",
      "metadata": {
        "id": "cf340d90"
      },
      "source": [
        "## 1) Setup (Colab)\n",
        "Run installs, then imports.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "bbfdf4e2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bbfdf4e2",
        "outputId": "3b5651ac-aeae-429a-dd72-e9cdebebee98"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "USE_ST: True | USE_RERANK: True | USE_CAPTIONING: True\n",
            "Tesseract version: 4.1.1\n"
          ]
        }
      ],
      "source": [
        "# === Setup & Imports (Colab-friendly) ===\n",
        "import os, re, glob, json, math, html\n",
        "from dataclasses import dataclass\n",
        "from typing import List, Dict, Any, Optional\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# ---- Core deps ----\n",
        "!pip -q install pandas numpy scikit-learn\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import normalize\n",
        "\n",
        "# ---- Retrieval deps ----\n",
        "!pip -q install faiss-cpu rank-bm25\n",
        "import faiss\n",
        "from rank_bm25 import BM25Okapi\n",
        "\n",
        "# ---- Dense + rerank (optional) ----\n",
        "# Some environments may have version conflicts. We try to install, but fall back gracefully if needed.\n",
        "USE_ST = True\n",
        "USE_RERANK = True\n",
        "\n",
        "try:\n",
        "    from sentence_transformers import SentenceTransformer, CrossEncoder\n",
        "except Exception as e:\n",
        "    USE_ST = False\n",
        "    USE_RERANK = False\n",
        "    print(\"⚠️ sentence-transformers not available in this runtime. Falling back to TF-IDF for 'dense' retrieval.\")\n",
        "    print(\"   Error:\", e)\n",
        "\n",
        "print(\"USE_ST:\", USE_ST, \"| USE_RERANK:\", USE_RERANK)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "29c67007",
      "metadata": {
        "id": "29c67007"
      },
      "source": [
        "### 1.1 System dependencies (Colab/Linux)\n",
        "No extra system dependencies are required for openFDA API text ingestion.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "f3f30307",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3f30307",
        "outputId": "d3e0ac5f-e0ca-4219-a46d-e56a445fa79b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "System dependencies installed in Section 1.\n"
          ]
        }
      ],
      "source": [
        "# No extra system dependencies required\n",
        "print('System dependencies: none required for openFDA API text.')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9867888d",
      "metadata": {
        "id": "9867888d"
      },
      "source": [
        "### 1.2 Imports\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "81a8ce47",
      "metadata": {
        "id": "81a8ce47"
      },
      "source": [
        "> **Note:** Dependencies are installed and imported above. If you restart the runtime, re-run Sections 1–2."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "93606e0e",
      "metadata": {
        "id": "93606e0e"
      },
      "source": [
        "## 2) Configure openFDA API (drug labels)\n",
        "We will fetch data from the openFDA drug labeling API instead of local JSON files.\n",
        "\n",
        "- Base endpoint: https://api.fda.gov/drug/label.json\n",
        "- Query format: `search=field:term`\n",
        "- Use `limit` to control results (max 1000 per API call)\n",
        "- Matching records are returned under the `results` field\n",
        "\n",
        "Recommended today: start with a narrow query and a small limit.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "88fb6df8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "88fb6df8",
        "outputId": "af708602-cdd7-4d9e-9e05-1dc8e0806daa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ All expected PDFs and figures found under: dataset\n",
            "\n",
            "PDFs: 2 ['dataset/doc1.pdf', 'dataset/doc2.pdf']\n",
            "Images: 7 ['dataset/fig1.jpg', 'dataset/fig2.jpg', 'dataset/fig3.jpg', 'dataset/fig4.jpg', 'dataset/fig5.jpg', 'dataset/fig6.jpg', 'dataset/fig7.jpg']\n"
          ]
        }
      ],
      "source": [
        "# === Cell 2: openFDA API config ===\n",
        "OPENFDA_BASE_URL = \"https://api.fda.gov/drug/label.json\"\n",
        "OPENFDA_API_KEY = \"\"  # optional; get one for higher rate limits\n",
        "OPENFDA_SEARCH = \"drug_interactions:caffeine\"  # field:term\n",
        "OPENFDA_SORT = None  # e.g., \"effective_time:desc\"\n",
        "OPENFDA_LIMIT = 200  # max 1000 per API call\n",
        "OPENFDA_MAX_RECORDS = 2000  # total records across pages\n",
        "OPENFDA_PAUSE_S = 0.0  # add a small delay if you hit rate limits\n",
        "\n",
        "print(\"openFDA base:\", OPENFDA_BASE_URL)\n",
        "print(\"Search:\", OPENFDA_SEARCH)\n",
        "print(\"Limit:\", OPENFDA_LIMIT, \"| Max records:\", OPENFDA_MAX_RECORDS)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "nU_WFwwURKIF",
      "metadata": {
        "id": "nU_WFwwURKIF"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "6cba544b",
      "metadata": {
        "id": "6cba544b"
      },
      "source": [
        "## 3) Define 3 stakeholder questions (application-oriented)\n",
        "- **Q1/Q2:** require grounded text evidence  \n",
        "- **Q3:** ambiguous/missing evidence → system should say **Not enough evidence in the retrieved context.**\n",
        "\n",
        "Also add:\n",
        "- Must-cite evidence (record/section)\n",
        "- Success criteria (what a good answer must include)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "f2d49247",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f2d49247",
        "outputId": "e349e815-e5d8-451b-eab5-b0fc6ad2a0f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Q1: How did the COVID-19 pandemic impact resistant hospital-onset infections and deaths in the U.S. overall, and which pathogens had the largest hospital-onset increases (percent change)? Use Figure 5 for the overall impact and Figure 6 for pathogen-specific increases.\n",
            "Q2: From the 2019 Antibiotic Resistance Threats report: list the 'Urgent' threats (Figure 2) and state the total estimated annual deaths from antibiotic-resistant infections (Figure 3: at least 35,900).\n",
            "Q3: Do the provided reports give a projected economic cost to U.S. GDP in 2050 for antimicrobial resistance? If not, say: Not enough evidence in the retrieved context.\n"
          ]
        }
      ],
      "source": [
        "QUERIES = [\n",
        "    {\n",
        "        \"id\": \"Q1\",\n",
        "        \"question\": (\n",
        "            \"For caffeine-containing products, what drug interactions are listed and where are they described in the label?\"\n",
        "        ),\n",
        "        \"must_cite\": [\n",
        "            \"drug_interactions\"\n",
        "        ],\n",
        "        \"success_criteria\": [\n",
        "            \"Summarize listed interactions and cite the drug_interactions section.\"\n",
        "        ],\n",
        "        \"keywords\": [\n",
        "            \"caffeine\", \"drug interactions\", \"drug_interactions\"\n",
        "        ]\n",
        "    },\n",
        "    {\n",
        "        \"id\": \"Q2\",\n",
        "        \"question\": (\n",
        "            \"What dosage and administration guidance is provided for acetaminophen, and are there any key warnings?\"\n",
        "        ),\n",
        "        \"must_cite\": [\n",
        "            \"dosage_and_administration\",\n",
        "            \"warnings\"\n",
        "        ],\n",
        "        \"success_criteria\": [\n",
        "            \"Provide dosage guidance and cite dosage_and_administration.\",\n",
        "            \"Mention warnings and cite warnings.\"\n",
        "        ],\n",
        "        \"keywords\": [\n",
        "            \"acetaminophen\", \"dosage\", \"administration\", \"warnings\"\n",
        "        ]\n",
        "    },\n",
        "    {\n",
        "        \"id\": \"Q3\",\n",
        "        \"question\": (\n",
        "            \"Do the labels provide a projected economic cost to U.S. GDP in 2050 for antimicrobial resistance? \"\n",
        "            \"If not, say: Not enough evidence in the retrieved context.\"\n",
        "        ),\n",
        "        \"must_cite\": [],\n",
        "        \"success_criteria\": [\n",
        "            \"Not enough evidence in the retrieved context.\"\n",
        "        ],\n",
        "        \"keywords\": [\"GDP\", \"2050\", \"economic cost\", \"antimicrobial resistance\"]\n",
        "    }\n",
        "]\n",
        "\n",
        "for q in QUERIES:\n",
        "    print(f\"{q['id']}: {q['question']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "98d2299c",
      "metadata": {
        "id": "98d2299c"
      },
      "source": [
        "## 4) Fetch openFDA data (text fields)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "42af3204",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "42af3204",
        "outputId": "c0e06925-15c3-4bb1-bc4e-cdd8f23173a5",
        "tags": [
          "Ingest cell"
        ]
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total PDF page chunks: 194\n",
            "Sample: doc1.pdf::p1 ANTIBIOTIC RESISTANCE THREATS IN THE UNITED STATES 2019 Revised Dec. 2019\n"
          ]
        }
      ],
      "source": [
        "# ---- openFDA field config ----\n",
        "OPENFDA_FIELD_ALLOWLIST = [\n",
        "    \"active_ingredient\",\n",
        "    \"description\",\n",
        "    \"dosage_and_administration\",\n",
        "    \"drug_interactions\",\n",
        "    \"information_for_patients\",\n",
        "    \"when_using\",\n",
        "    \"overdosage\",\n",
        "    \"stop_use\",\n",
        "    \"user_safety_warnings\",\n",
        "    \"warnings\",\n",
        "]\n",
        "OPENFDA_FIELD_BLOCKLIST = {\"spl_product_data_elements\"}  # noisy by default\n",
        "INCLUDE_TABLE_FIELDS = False\n",
        "MAX_RECORDS = None  # set an int for faster iteration during dev\n",
        "MIN_CHARS = 40\n",
        "\n",
        "# ---- Module import (openfda_rag) ----\n",
        "from openfda_rag import (\n",
        "    TextChunk,\n",
        "    pick_text_fields,\n",
        "    derive_doc_id,\n",
        "    iter_openfda_records,\n",
        "    build_openfda_query,\n",
        "    tokenize,\n",
        ")\n",
        "\n",
        "if \"OPENFDA_SEARCH\" not in globals():\n",
        "    OPENFDA_SEARCH = \"drug_interactions:caffeine\"\n",
        "\n",
        "# Optional: build a query from a prompt if you set OPENFDA_SEARCH = \"AUTO\"\n",
        "if OPENFDA_SEARCH == \"AUTO\":\n",
        "    seed_text = QUERIES[0][\"question\"] if \"QUERIES\" in globals() else \"drug interactions\"\n",
        "    OPENFDA_SEARCH = build_openfda_query(seed_text, fields=OPENFDA_FIELD_ALLOWLIST)\n",
        "\n",
        "records = list(\n",
        "    iter_openfda_records(\n",
        "        search=OPENFDA_SEARCH,\n",
        "        api_key=OPENFDA_API_KEY or None,\n",
        "        base_url=OPENFDA_BASE_URL,\n",
        "        limit=OPENFDA_LIMIT,\n",
        "        max_records=OPENFDA_MAX_RECORDS,\n",
        "        sort=OPENFDA_SORT,\n",
        "        pause_s=OPENFDA_PAUSE_S,\n",
        "    )\n",
        ")\n",
        "\n",
        "if MAX_RECORDS:\n",
        "    records = records[:MAX_RECORDS]\n",
        "\n",
        "record_chunks = []\n",
        "for i, rec in enumerate(records):\n",
        "    doc_id = derive_doc_id(rec, i)\n",
        "    for field, text in pick_text_fields(\n",
        "        rec, OPENFDA_FIELD_ALLOWLIST, OPENFDA_FIELD_BLOCKLIST, INCLUDE_TABLE_FIELDS\n",
        "    ).items():\n",
        "        if len(text) < MIN_CHARS:\n",
        "            continue\n",
        "        chunk_id = f\"{doc_id}::{field}\"\n",
        "        record_chunks.append(TextChunk(chunk_id, doc_id, field, text))\n",
        "\n",
        "print(\"Records:\", len(records))\n",
        "print(\"Text chunks:\", len(record_chunks))\n",
        "if record_chunks:\n",
        "    print(\"Sample:\", record_chunks[0].chunk_id, record_chunks[0].text[:250])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3e7cca6a",
      "metadata": {
        "id": "3e7cca6a"
      },
      "source": [
        "## 5) Images skipped (openFDA text-only)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "dffe2ffa",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dffe2ffa",
        "outputId": "5df26bb4-d8d7-4ab3-a3ba-49429fbd6846"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evidence items: 7\n",
            "Sample OCR: fig1.jpg QCOVID-19 Impacts on 18 Xi ntimicrobial-Resistant Bacteria and Fungi oO clhreat Estimates wn 3The following table summarizes the latest national death and infection estimates for 18 antimicrobial-resi\n"
          ]
        }
      ],
      "source": [
        "# No image ingestion for openFDA labels (text-only)\n",
        "print(\"Image ingestion skipped (openFDA labels are text-only).\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d2fa100d",
      "metadata": {
        "id": "d2fa100d"
      },
      "source": [
        "### 5.1 Optional captioning (not applicable)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "5ed7e22b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ed7e22b",
        "outputId": "91dad589-30d6-4c48-83f2-746505734298"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Captioning skipped.\n"
          ]
        }
      ],
      "source": [
        "print(\"Captioning skipped (no images).\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cf21da5a",
      "metadata": {
        "id": "cf21da5a"
      },
      "source": [
        "## 6) Chunking (record/section vs fixed-size)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "cb23d1ea",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cb23d1ea",
        "outputId": "62bd5423-b460-41db-ad04-2c6b9ffec333"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Page chunks: 194\n",
            "Fixed-size chunks: 346\n"
          ]
        }
      ],
      "source": [
        "from openfda_rag import SubChunk, fixed_size_chunk\n",
        "\n",
        "sub_chunks = []\n",
        "for rc in record_chunks:\n",
        "    for j, t in enumerate(fixed_size_chunk(rc.text, 250, 40)):\n",
        "        sub_chunks.append(SubChunk(f\"{rc.chunk_id}::c{j+1}\", rc.doc_id, rc.field, t))\n",
        "\n",
        "print(\"Record chunks:\", len(record_chunks))\n",
        "print(\"Fixed-size chunks:\", len(sub_chunks))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a1edd109",
      "metadata": {},
      "source": [
        "### Optional: Build preprocessing artifacts (API)\n",
        "Run this once to create the `preprocessed/` artifacts from the openFDA API query in Section 2.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd9e5882",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Optional: build preprocessing artifacts from openFDA API (skip if already built)\n",
        "from openfda_rag import build_artifacts\n",
        "\n",
        "artifacts = build_artifacts(\n",
        "    api_search=OPENFDA_SEARCH,\n",
        "    output_dir=\"preprocessed\",\n",
        "    field_allowlist=OPENFDA_FIELD_ALLOWLIST,\n",
        "    field_blocklist=OPENFDA_FIELD_BLOCKLIST,\n",
        "    include_table_fields=INCLUDE_TABLE_FIELDS,\n",
        "    min_chars=MIN_CHARS,\n",
        "    use_st=USE_ST,\n",
        "    save=True,\n",
        "    api_key=OPENFDA_API_KEY or None,\n",
        "    api_base_url=OPENFDA_BASE_URL,\n",
        "    api_limit=OPENFDA_LIMIT,\n",
        "    api_max_records=OPENFDA_MAX_RECORDS,\n",
        "    api_sort=OPENFDA_SORT,\n",
        "    api_pause_s=OPENFDA_PAUSE_S,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0e003631",
      "metadata": {},
      "source": [
        "### Optional: Load preprocessed artifacts\n",
        "If you built `preprocessed/` from the openFDA API, you can load its artifacts here and skip Sections 4–7.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "40e4dfd9",
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "from openfda_rag import load_artifacts\n",
        "\n",
        "PREPROCESSED_DIR = \"preprocessed\"\n",
        "artifacts = load_artifacts(PREPROCESSED_DIR)\n",
        "\n",
        "record_chunks = artifacts[\"record_chunks\"]\n",
        "sub_chunks = artifacts[\"sub_chunks\"]\n",
        "faiss_A = artifacts[\"faiss_A\"]\n",
        "faiss_B = artifacts[\"faiss_B\"]\n",
        "bm25_A = artifacts[\"bm25_A\"]\n",
        "bm25_B = artifacts[\"bm25_B\"]\n",
        "\n",
        "TEXT_CORPUS_A = record_chunks\n",
        "TEXT_CORPUS_B = sub_chunks\n",
        "\n",
        "PREPROCESSED_LOADED = True\n",
        "manifest = artifacts[\"manifest\"]\n",
        "embedder_type = (manifest.get(\"embedder\") or {}).get(\"type\")\n",
        "embedder_model = (manifest.get(\"embedder\") or {}).get(\"model\")\n",
        "\n",
        "_dim = faiss_A.d if faiss_A is not None else 1\n",
        "\n",
        "if embedder_type == \"sentence_transformers\":\n",
        "    from sentence_transformers import SentenceTransformer\n",
        "\n",
        "    embedder = SentenceTransformer(embedder_model or \"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "\n",
        "    def embed_texts(texts, batch_size: int = 32):\n",
        "        return embedder.encode(\n",
        "            texts,\n",
        "            batch_size=batch_size,\n",
        "            show_progress_bar=False,\n",
        "            convert_to_numpy=True,\n",
        "            normalize_embeddings=True,\n",
        "        )\n",
        "elif embedder_type == \"tfidf\":\n",
        "    from sklearn.preprocessing import normalize\n",
        "\n",
        "    vectorizer = artifacts.get(\"vectorizer\")\n",
        "\n",
        "    def embed_texts(texts, batch_size: int = 32):\n",
        "        if vectorizer is None:\n",
        "            return np.zeros((len(texts), _dim), dtype=np.float32)\n",
        "        X = normalize(vectorizer.transform(texts))\n",
        "        return X.toarray().astype(np.float32)\n",
        "else:\n",
        "    def embed_texts(texts, batch_size: int = 32):\n",
        "        return np.zeros((len(texts), _dim), dtype=np.float32)\n",
        "\n",
        "print(\"Loaded artifacts:\", len(record_chunks), \"record chunks |\", len(sub_chunks), \"sub-chunks\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0840be09",
      "metadata": {
        "id": "0840be09"
      },
      "source": [
        "## 7) Indexing & retrieval (dense + sparse + rerank)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "45b3a871",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "49a291aa2957423aafabd41e0068e272",
            "caf09549816840c7992d82d272b6b980",
            "5cc1687838e94b09a054ce4fc518d96a",
            "93ed0ba025bc4c7b99dfee1f077749fe",
            "f4404319d4a247f29f2cb9ef0d0c1195",
            "098f9f5ea4a9439c90c3fac8c62a5a18",
            "7722d535af8a4cc9b21146d9d5c6011c",
            "8d0ce16a5a7a4503beee4630cd773e2c",
            "a6119c94dc144cf19c9d3f25996cebbb",
            "81e764d57070462b9bf518c07b6ed5c4",
            "7d55010d2aca4e558c427b85b7ccc899"
          ]
        },
        "id": "45b3a871",
        "outputId": "ccf90a82-8a59-4b91-b4c2-14ddb1fa1ad5"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "49a291aa2957423aafabd41e0068e272",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading weights:   0%|          | 0/103 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Indexes ready.\n"
          ]
        }
      ],
      "source": [
        "import os, re, warnings\n",
        "from typing import List\n",
        "import numpy as np\n",
        "\n",
        "def tokenize(text: str) -> List[str]:\n",
        "    return [t.lower() for t in re.findall(r\"[a-zA-Z0-9]+\", text)]\n",
        "os.environ[\"TRANSFORMERS_NO_ADVISORY_WARNINGS\"] = \"1\"\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
        "os.environ[\"HF_HUB_DISABLE_PROGRESS_BARS\"] = \"1\"\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", message=\"The secret `HF_TOKEN` does not exist*\")\n",
        "warnings.filterwarnings(\"ignore\", message=\"You are sending unauthenticated requests*\")\n",
        "\n",
        "try:\n",
        "    from transformers.utils import logging as hf_logging\n",
        "    hf_logging.set_verbosity_error()\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "try:\n",
        "    from huggingface_hub.utils import logging as hub_logging\n",
        "    hub_logging.set_verbosity_error()\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "if \"PREPROCESSED_LOADED\" in globals() and PREPROCESSED_LOADED:\n",
        "    print(\"Using preprocessed artifacts; skipping indexing.\")\n",
        "else:\n",
        "    # --- Embeddings (dense retrieval) ---\n",
        "    # If SentenceTransformers is available, we use it. Otherwise, we fall back to TF-IDF vectors.\n",
        "    if USE_ST:\n",
        "        embedder = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "\n",
        "        def embed_texts(texts: List[str], batch_size: int = 32) -> np.ndarray:\n",
        "            return embedder.encode(\n",
        "                texts,\n",
        "                batch_size=batch_size,\n",
        "                show_progress_bar=False,\n",
        "                convert_to_numpy=True,\n",
        "                normalize_embeddings=True\n",
        "            )\n",
        "    else:\n",
        "        tfidf_vec = TfidfVectorizer(max_features=50000, ngram_range=(1, 2))\n",
        "        _tfidf_fitted = False\n",
        "\n",
        "        def embed_texts(texts: List[str], batch_size: int = 32) -> np.ndarray:\n",
        "            global _tfidf_fitted\n",
        "            X = tfidf_vec.fit_transform(texts) if not _tfidf_fitted else tfidf_vec.transform(texts)\n",
        "            _tfidf_fitted = True\n",
        "            X = normalize(X)\n",
        "            return X.toarray().astype(np.float32)\n",
        "\n",
        "    def build_faiss_ip(vectors: np.ndarray):\n",
        "        dim = vectors.shape[1]\n",
        "        index = faiss.IndexFlatIP(dim)\n",
        "        index.add(vectors.astype(np.float32))\n",
        "        return index\n",
        "\n",
        "    TEXT_CORPUS_A = record_chunks\n",
        "    TEXT_CORPUS_B = sub_chunks\n",
        "\n",
        "    texts_A = [c.text for c in TEXT_CORPUS_A]\n",
        "    vecs_A = embed_texts(texts_A) if texts_A else np.zeros((0, 384), dtype=np.float32)\n",
        "    faiss_A = build_faiss_ip(vecs_A) if len(texts_A) > 0 else None\n",
        "    bm25_A = BM25Okapi([tokenize(t) for t in texts_A]) if len(texts_A) > 0 else None\n",
        "\n",
        "    texts_B = [c.text for c in TEXT_CORPUS_B]\n",
        "    vecs_B = embed_texts(texts_B) if texts_B else np.zeros((0, 384), dtype=np.float32)\n",
        "    faiss_B = build_faiss_ip(vecs_B) if len(texts_B) > 0 else None\n",
        "    bm25_B = BM25Okapi([tokenize(t) for t in texts_B]) if len(texts_B) > 0 else None\n",
        "\n",
        "    print(\"Indexes ready.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "2VkXBfPmUUdP",
      "metadata": {
        "id": "2VkXBfPmUUdP"
      },
      "outputs": [],
      "source": [
        "import os, warnings\n",
        "os.environ[\"HF_HUB_DISABLE_PROGRESS_BARS\"] = \"1\"\n",
        "os.environ[\"TRANSFORMERS_NO_ADVISORY_WARNINGS\"] = \"1\"\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", message=\"You are sending unauthenticated requests*\")\n",
        "warnings.filterwarnings(\"ignore\", message=\"The secret `HF_TOKEN` does not exist*\")\n",
        "\n",
        "try:\n",
        "    from transformers.utils import logging as hf_logging\n",
        "    hf_logging.set_verbosity_error()\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "try:\n",
        "    from huggingface_hub.utils import logging as hub_logging\n",
        "    hub_logging.set_verbosity_error()\n",
        "except Exception:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "92192462",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "03d3dcff956046ac868c1ef42d23048e",
            "442e5f6527b34a4db3ec2eff92860fcc",
            "9417759bb9cb466c82d964a11c6db6b0",
            "583b0729373445649c53f84213137e5d",
            "6f1bce9f804a4260862840538817b0ba",
            "87a9b2e37b5945589898aee5adaf0f78",
            "765e4e01ec7e442a93049d6f02f47c08",
            "c2d2f32bcd424442b3f0a3acae967056",
            "afef67ebe3334645a48f3f38dc12f421",
            "c1dedb3a154c42089a808fa8e549c21d",
            "af50bc305afe4112a77a1c1d1c8c8ca8"
          ]
        },
        "id": "92192462",
        "outputId": "7ee426bd-9c13-4a44-e07f-69ddf8fb5001"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "03d3dcff956046ac868c1ef42d23048e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading weights:   0%|          | 0/105 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "def dense_search(query: str, index, corpus, top_k: int = 5):\n",
        "    if index is None or len(corpus)==0:\n",
        "        return []\n",
        "    qv = embed_texts([query])\n",
        "    scores, idxs = index.search(qv.astype(np.float32), top_k)\n",
        "    out = []\n",
        "    for s, i in zip(scores[0], idxs[0]):\n",
        "        if int(i) >= 0:\n",
        "            out.append((float(s), corpus[int(i)]))\n",
        "    return out\n",
        "\n",
        "def sparse_search(query: str, bm25, corpus, top_k: int = 5):\n",
        "    if bm25 is None or len(corpus)==0:\n",
        "        return []\n",
        "    scores = bm25.get_scores(tokenize(query))\n",
        "    top = np.argsort(scores)[::-1][:top_k]\n",
        "    return [(float(scores[i]), corpus[int(i)]) for i in top]\n",
        "\n",
        "def hybrid_fuse(dense_res, sparse_res, alpha: float = 0.5, top_k: int = 5):\n",
        "    def k(item): return getattr(item, \"chunk_id\", str(item))\n",
        "    dense_rank = {k(it): r for r, (_, it) in enumerate(dense_res, start=1)}\n",
        "    sparse_rank = {k(it): r for r, (_, it) in enumerate(sparse_res, start=1)}\n",
        "    keys = set(dense_rank) | set(sparse_rank)\n",
        "    fused = []\n",
        "    for key in keys:\n",
        "        dr = dense_rank.get(key, len(dense_res)+1)\n",
        "        sr = sparse_rank.get(key, len(sparse_res)+1)\n",
        "        score = alpha*(1.0/dr) + (1-alpha)*(1.0/sr)\n",
        "        obj = next((it for _, it in dense_res if k(it)==key), None) or next((it for _, it in sparse_res if k(it)==key), None)\n",
        "        fused.append((score, obj))\n",
        "    fused.sort(key=lambda x: x[0], reverse=True)\n",
        "    return fused[:top_k]\n",
        "\n",
        "# --- Reranker (optional) ---\n",
        "reranker = None\n",
        "if USE_ST and USE_RERANK:\n",
        "    try:\n",
        "        reranker = CrossEncoder(\"cross-encoder/ms-marco-MiniLM-L-6-v2\")\n",
        "    except Exception as e:\n",
        "        reranker = None\n",
        "        USE_RERANK = False\n",
        "        print(\"⚠️ Reranker unavailable, continuing without reranking. Error:\", e)\n",
        "\n",
        "\n",
        "def rerank(query: str, items, get_text, top_k=5):\n",
        "    if reranker is None:\n",
        "        return list(items)[:top_k]\n",
        "\n",
        "    if not items:\n",
        "        return []\n",
        "    scores = reranker.predict([(query, get_text(it)) for it in items])\n",
        "    ranked = sorted(zip(scores, items), key=lambda x: x[0], reverse=True)\n",
        "    return [it for _, it in ranked[:top_k]]\n",
        "\n",
        "def retrieve_text(query: str, chunking: str = \"record\", method: str = \"hybrid\", top_k: int = 5, alpha: float = 0.5, use_rerank: bool = True):\n",
        "    if chunking in (\"record\", \"page\"):\n",
        "        corpus, index, bm25 = TEXT_CORPUS_A, faiss_A, bm25_A\n",
        "    else:\n",
        "        corpus, index, bm25 = TEXT_CORPUS_B, faiss_B, bm25_B\n",
        "\n",
        "    if method == \"dense\":\n",
        "        res = dense_search(query, index, corpus, top_k=max(10, top_k))\n",
        "        items = [it for _, it in res]\n",
        "    elif method == \"sparse\":\n",
        "        res = sparse_search(query, bm25, corpus, top_k=max(10, top_k))\n",
        "        items = [it for _, it in res]\n",
        "    else:\n",
        "        d = dense_search(query, index, corpus, top_k=max(10, top_k))\n",
        "        s = sparse_search(query, bm25, corpus, top_k=max(10, top_k))\n",
        "        res = hybrid_fuse(d, s, alpha=alpha, top_k=max(10, top_k))\n",
        "        items = [it for _, it in res]\n",
        "\n",
        "    if use_rerank:\n",
        "        return rerank(query, items, lambda it: it.text, top_k=top_k)\n",
        "    return items[:top_k]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "68bbdcd5",
      "metadata": {
        "id": "68bbdcd5"
      },
      "source": [
        "## 8) Evidence pack + citations (text-only)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "da1803c9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "da1803c9",
        "outputId": "448b6116-0f6d-472b-cdd6-b8be53177b56"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[doc2.pdf p17] text COVID-19: U.S. Impact on Antimicrobial Resistance, Special Report 2022 17 Carbapenem-resistant Acinetobacter A threat to\n",
            "[doc2.pdf p16] text COVID-19: U.S. Impact on Antimicrobial Resistance, Special Report 2022 16 Resistant Pathogen 2017 Threat Estimate 2018 T\n",
            "[doc2.pdf p7] text COVID-19: U.S. Impact on Antimicrobial Resistance, Special Report 2022 7 Antimicrobial-resistant infections are amplifie\n",
            "[doc2.pdf p3] text COVID-19: U.S. Impact on Antimicrobial Resistance, Special Report 2022 3 Foreword As an infectious disease physician, I \n",
            "[fig2.jpg] figure Z Resistant Pathogen 2017 2018 2019 2017-2019 2020 Threat Estimate and g Threat Estimate Threat Estimate Threat Estimate\n",
            "[fig7.jpg] figure Resistant germ Threat What CDC Counted, What CDC Did Not Threat New 2013 Can Data be Year-to-Year iS ei eens Stee 2019 r\n",
            "[fig6.jpg] figure om o . Threat Estimates Cc This following table summarizes the 2019 MR Threats Report estimates, and compares these esti\n",
            "[fig5.jpg] figure The Threat of Antibiotic Resistance in the United States Antibiotic resistance—when germs (bacteria, fungi) develop the \n"
          ]
        }
      ],
      "source": [
        "def cite_text(it):\n",
        "    return f\"[{it.chunk_id}]\"\n",
        "\n",
        "def build_evidence_pack(question: str, q_keywords=None, chunking=\"record\", method=\"hybrid\",\n",
        "                        top_k_text=4):\n",
        "    query = question if not q_keywords else question + \" \" + \" \".join(q_keywords)\n",
        "    txt = retrieve_text(query, chunking=chunking, method=method,\n",
        "                        top_k=top_k_text, use_rerank=True)\n",
        "\n",
        "    pack = []\n",
        "    for it in txt:\n",
        "        pack.append({\"type\": \"text\", \"cite\": cite_text(it), \"content\": it.text[:800]})\n",
        "    return pack\n",
        "\n",
        "ep = build_evidence_pack(\n",
        "    QUERIES[0][\"question\"],\n",
        "    q_keywords=QUERIES[0][\"keywords\"]\n",
        ")\n",
        "\n",
        "for e in ep:\n",
        "    print(e[\"cite\"], e[\"type\"], e[\"content\"][:120])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a55b697d",
      "metadata": {
        "id": "a55b697d"
      },
      "source": [
        "## 9) Grounded response (LLM/VLM) — connect Gemini/HF if available\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "64b30735",
      "metadata": {
        "id": "64b30735"
      },
      "outputs": [],
      "source": [
        "# 9) Grounded response (LLM/VLM optional) — BEST FALLBACK VERSION (no external API needed)\n",
        "\n",
        "def rag_prompt(question: str, evidence_pack: list) -> str:\n",
        "    evidence_lines = [f'{e[\"cite\"]} {e[\"content\"]}' for e in evidence_pack]\n",
        "    evidence_block = \"\\n\\n\".join(evidence_lines)\n",
        "    return f\"\"\"You are a grounded assistant. Use ONLY the evidence below.\n",
        "Every key claim must cite evidence like [record_id::field::c#].\n",
        "If the evidence is insufficient, respond exactly:\n",
        "Not enough evidence in the retrieved context.\n",
        "\n",
        "Evidence:\n",
        "{evidence_block}\n",
        "\n",
        "Question:\n",
        "{question}\n",
        "\n",
        "Answer (with citations):\n",
        "\"\"\"\n",
        "\n",
        "def _evidence_is_insufficient(question: str, evidence_pack: list) -> bool:\n",
        "    # Heuristic: too little evidence, or mostly empty/noisy snippets\n",
        "    if not evidence_pack or len(evidence_pack) < 2:\n",
        "        return True\n",
        "    total_chars = sum(len((e.get(\"content\") or \"\").strip()) for e in evidence_pack)\n",
        "    if total_chars < 400:\n",
        "        return True\n",
        "\n",
        "    # If OCR is super noisy, it can inflate chars; require at least some alpha tokens overall\n",
        "    blob = \" \".join((e.get(\"content\") or \"\") for e in evidence_pack)\n",
        "    alpha_tokens = re.findall(r\"[A-Za-z]{3,}\", blob)\n",
        "    return len(alpha_tokens) < 60\n",
        "\n",
        "def _missing_required_terms(question: str, evidence_pack: list) -> bool:\n",
        "    \"\"\"\n",
        "    Query-aware refusal gate:\n",
        "    If the question asks for GDP/economic cost projections for 2050,\n",
        "    require those specific anchors to appear in retrieved evidence.\n",
        "    \"\"\"\n",
        "    q = question.lower()\n",
        "    blob = \" \".join((e.get(\"content\") or \"\").lower() for e in evidence_pack)\n",
        "\n",
        "    # If user asks about GDP, we must see \"gdp\" in evidence\n",
        "    if \"gdp\" in q and \"gdp\" not in blob:\n",
        "        return True\n",
        "\n",
        "    # If user asks about 2050, we must see \"2050\" in evidence\n",
        "    if \"2050\" in q and \"2050\" not in blob:\n",
        "        return True\n",
        "\n",
        "    # If question is explicitly economic/cost, require an economic signal too\n",
        "    if any(t in q for t in [\"economic\", \"economy\", \"cost\"]):\n",
        "        econ_signals = [\"economic\", \"economy\", \"cost\", \"billion\", \"trillion\", \"usd\", \"$\", \"percent\", \"%\"]\n",
        "        if not any(s in blob for s in econ_signals):\n",
        "            return True\n",
        "\n",
        "    return False\n",
        "\n",
        "def _sentences_from_pack(evidence_pack: list) -> list:\n",
        "    \"\"\"Return [(sentence, cite)] pairs from evidence pack.\"\"\"\n",
        "    out = []\n",
        "    for e in evidence_pack:\n",
        "        cite = e[\"cite\"]\n",
        "        text = (e.get(\"content\") or \"\").strip()\n",
        "        if not text:\n",
        "            continue\n",
        "        # sentence-ish splitting (works OK for label text)\n",
        "        parts = re.split(r\"(?<=[.!?])\\s+|\\n+\", text)\n",
        "        for s in parts:\n",
        "            s = s.strip()\n",
        "            if len(s) >= 40:\n",
        "                out.append((s, cite))\n",
        "    return out\n",
        "\n",
        "def generate_answer(question: str, evidence_pack: Optional[list] = None, max_sentences: int = 4) -> str:\n",
        "    \"\"\"\n",
        "    Fallback grounded answer generator:\n",
        "    - Enforces refusal when evidence is insufficient or missing required terms\n",
        "    - Otherwise selects high-overlap sentences and formats them with citations\n",
        "    \"\"\"\n",
        "    if evidence_pack is None:\n",
        "        return \"Not enough evidence in the retrieved context.\"\n",
        "\n",
        "    if _evidence_is_insufficient(question, evidence_pack) or _missing_required_terms(question, evidence_pack):\n",
        "        return \"Not enough evidence in the retrieved context.\"\n",
        "\n",
        "    q_tokens = set(tokenize(question))\n",
        "    candidates = []\n",
        "    for sent, cite in _sentences_from_pack(evidence_pack):\n",
        "        s_tokens = set(tokenize(sent))\n",
        "        overlap = len(q_tokens & s_tokens)\n",
        "        # Light boost for numeric facts (helps for % / counts)\n",
        "        has_number = bool(re.search(r\"\\d\", sent))\n",
        "        score = overlap + (2 if has_number else 0)\n",
        "        candidates.append((score, sent, cite))\n",
        "\n",
        "    candidates.sort(key=lambda x: x[0], reverse=True)\n",
        "\n",
        "    picked = []\n",
        "    used = set()\n",
        "    for score, sent, cite in candidates:\n",
        "        if score <= 0:\n",
        "            continue\n",
        "        key = (sent[:80].lower(), cite)\n",
        "        if key in used:\n",
        "            continue\n",
        "        used.add(key)\n",
        "        picked.append(f\"{sent} {cite}\")\n",
        "        if len(picked) >= max_sentences:\n",
        "            break\n",
        "\n",
        "    if not picked:\n",
        "        return \"Not enough evidence in the retrieved context.\"\n",
        "\n",
        "    return \"\\n\".join(picked)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "677444a1",
      "metadata": {
        "id": "677444a1"
      },
      "source": [
        "## 10) Demo loop (stakeholder-facing)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "6f6db4b5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6f6db4b5",
        "outputId": "5258456a-db50-450c-d890-03c1fbd9ff9c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "===  Q1  ===\n",
            "Q: How did the COVID-19 pandemic impact the rates of resistant hospital-onset infections and deaths in the U.S., and which specific pathogens saw the most significant increases?\n",
            "Must-cite: ['doc2.pdf (COVID-19 Special Report 2022)', 'fig5.jpg (Overall impact statistics)', 'fig6.jpg (Pathogen specific increases)']\n",
            "Top evidence citations: ['[doc2.pdf p17]', '[doc2.pdf p16]', '[doc2.pdf p7]', '[doc2.pdf p3]', '[fig2.jpg]', '[fig7.jpg]', '[fig6.jpg]', '[fig5.jpg]']\n",
            "Answer:\n",
            " Impact on Antimicrobial Resistance, Special Report 2022 16 Resistant Pathogen 2017 Threat Estimate 2018 Threat Estimate 2019 Threat Estimate 2017-2019 Change 2020 Threat Estimate and 2019-2020 Change Multidrug-resistant Pseudomonas aeruginosa 32,600 cases 2,700 deaths 29,500 cases 2,500 deaths 28,200 cases 2,400 deaths 28,800 cases 2,500 deaths Overall: Stable* Hospital-onset: 32% increase* Drug-resistant nontyphoidal Salmonella 212,500 infections 70 deaths 228,290 infections 254,810 infections Increase Data delayed due to COVID-19 pandemic‡ 14% of infections were resistant, a 3% decrease Drug-resistant Salmonella serotype Typhi 4,100 infections <5 deaths 4,640 infections 6,130 infections Increase Data delayed due to COVID-19 pandemic‡ 85% of infections were resistant, a 10% [doc2.pdf p16]\n",
            "Z Resistant Pathogen 2017 2018 2019 2017-2019 2020 Threat Estimate and g Threat Estimate Threat Estimate Threat Estimate Change 2019-2020 Change ; 28,800 cases Multidrug-resistant 32,600 cases 29,500 cases 28,200 cases yr 2,500 deaths Pseudomonas aeruginosa 2,700 deaths 2,500 deaths 2,400 deaths Decrease* Overall: Stable* Hospital-onset: 32% increase* Drug-resistant 212.500 infections Data delayed due to COVID-19 nontyphoidal , 228,290 infections 254,810 infections Lin pandemict 14% of infections were 70 deaths . [fig2.jpg]\n",
            "Antimicrobial resistance was one of our greatest public health concerns prior to the COVID-19 pandemic, and it remains so. [doc2.pdf p3]\n",
            "The inpatient population in 2020 was very different from the pre-pandemic population—hospitals saw higher numbers of sicker patients (hospitalization could not be avoided) who needed an extended length of stay. [doc2.pdf p7]\n",
            "\n",
            "===  Q2  ===\n",
            "Q: According to the 2019 baseline data, what are the designated 'Urgent' antibiotic resistance threats and what is the total estimated annual mortality burden associated with AR in the U.S.?\n",
            "Must-cite: ['doc1.pdf (2019 AR Threats Report)', 'fig2.jpg (List of Urgent Threats)', 'fig3.jpg (Mortality estimates)']\n",
            "Top evidence citations: ['[doc1.pdf p7]', '[doc1.pdf p25]', '[doc1.pdf p2]', '[doc2.pdf p34]', '[fig5.jpg]', '[fig7.jpg]', '[fig6.jpg]', '[fig1.jpg]']\n",
            "Answer:\n",
            " A Ela (edit) i dt Each year, antibiotic-resistant Clostridioides difficile** is bacteria and fungi cause at a related to antibiotic use and least an estimated: antibiotic resistance: Fe 2,868,700 223,900 infections cases ®, 35,900 coms = B, 125800 acatn New Antibiotic Resistance Threats List Updated urgent, serious, and concerning threats—totaling 18 5 2 wate 3 urgent threats A ete Watch List with threats ig Antibiotic resistance remains a significant One Health problem, affecting humans, animals, and the environment. [fig5.jpg]\n",
            "Antibiotic Resistance Threats in the United States, 2019 vii Executive Summary CDC’s Antibiotic Resistance Threats in the United States, 2019 (2019 AR Threats Report) includes updated national death and infection estimates that underscore the continued threat of antibiotic resistance in the United States. [doc1.pdf p7]\n",
            "Antibiotic Resistance Threats in the United States, 2019 (2019 AR Threats Report) is a publication of the Antibiotic Resistance Coordination and Strategy Unit within the Division of Healthcare Quality Promotion, National Center for Emerging and Zoonotic Infectious Diseases, Centers for Disease Control and Prevention. [doc1.pdf p2]\n",
            "New CDC data show that while the burden of antibiotic-resistance threats in the United States was greater than initially understood, deaths are decreasing since the 2013 report. [doc1.pdf p7]\n",
            "\n",
            "===  Q3  ===\n",
            "Q: What is the projected economic cost of antimicrobial resistance to the U.S. GDP for the year 2050 based on the provided reports?\n",
            "Must-cite: []\n",
            "Top evidence citations: ['[doc2.pdf p3]', '[doc2.pdf p15]', '[doc2.pdf p1]', '[doc2.pdf p29]', '[fig5.jpg]', '[fig7.jpg]', '[fig2.jpg]', '[fig6.jpg]']\n",
            "Answer:\n",
            " Not enough evidence in the retrieved context.\n"
          ]
        }
      ],
      "source": [
        "from openfda_rag import build_artifacts, build_openfda_query\n",
        "\n",
        "\n",
        "def _embed_query(query: str, embedder_type: str, embedder_model: Optional[str], vectorizer):\n",
        "    if embedder_type == \"sentence_transformers\":\n",
        "        from sentence_transformers import SentenceTransformer\n",
        "\n",
        "        if not hasattr(_embed_query, \"_cache\"):\n",
        "            _embed_query._cache = {}\n",
        "        model_name = embedder_model or \"sentence-transformers/all-MiniLM-L6-v2\"\n",
        "        if model_name not in _embed_query._cache:\n",
        "            _embed_query._cache[model_name] = SentenceTransformer(model_name)\n",
        "        embedder = _embed_query._cache[model_name]\n",
        "        return embedder.encode([query], convert_to_numpy=True, normalize_embeddings=True)\n",
        "\n",
        "    if embedder_type == \"tfidf\" and vectorizer is not None:\n",
        "        return normalize(vectorizer.transform([query])).toarray().astype(np.float32)\n",
        "\n",
        "    return None\n",
        "\n",
        "\n",
        "def retrieve_from_api(\n",
        "    prompt: str,\n",
        "    keywords: Optional[List[str]] = None,\n",
        "    search: Optional[str] = None,\n",
        "    fields: Optional[List[str]] = None,\n",
        "    chunking: str = \"record\",\n",
        "    method: str = \"hybrid\",\n",
        "    top_k: int = 4,\n",
        "    alpha: float = 0.5,\n",
        "    use_rerank: bool = True,\n",
        "    api_max_records: Optional[int] = None,\n",
        "):\n",
        "    query_text = prompt if not keywords else prompt + \" \" + \" \".join(keywords)\n",
        "    search_query = search or build_openfda_query(\n",
        "        query_text, fields=fields or OPENFDA_FIELD_ALLOWLIST\n",
        "    )\n",
        "\n",
        "    artifacts = build_artifacts(\n",
        "        api_search=search_query,\n",
        "        field_allowlist=OPENFDA_FIELD_ALLOWLIST,\n",
        "        field_blocklist=OPENFDA_FIELD_BLOCKLIST,\n",
        "        include_table_fields=INCLUDE_TABLE_FIELDS,\n",
        "        min_chars=MIN_CHARS,\n",
        "        use_st=USE_ST,\n",
        "        save=False,\n",
        "        save_vectorizer=False,\n",
        "        api_key=OPENFDA_API_KEY or None,\n",
        "        api_base_url=OPENFDA_BASE_URL,\n",
        "        api_limit=OPENFDA_LIMIT,\n",
        "        api_max_records=api_max_records or OPENFDA_MAX_RECORDS,\n",
        "        api_sort=OPENFDA_SORT,\n",
        "        api_pause_s=OPENFDA_PAUSE_S,\n",
        "    )\n",
        "\n",
        "    if chunking in (\"record\", \"page\"):\n",
        "        corpus, index, bm25 = (\n",
        "            artifacts[\"record_chunks\"],\n",
        "            artifacts[\"faiss_A\"],\n",
        "            artifacts[\"bm25_A\"],\n",
        "        )\n",
        "    else:\n",
        "        corpus, index, bm25 = (\n",
        "            artifacts[\"sub_chunks\"],\n",
        "            artifacts[\"faiss_B\"],\n",
        "            artifacts[\"bm25_B\"],\n",
        "        )\n",
        "\n",
        "    embedder_type = (artifacts.get(\"manifest\", {}).get(\"embedder\") or {}).get(\"type\")\n",
        "    embedder_model = (artifacts.get(\"manifest\", {}).get(\"embedder\") or {}).get(\"model\")\n",
        "    vectorizer = artifacts.get(\"vectorizer\")\n",
        "\n",
        "    def local_dense_search(query: str, top_k_local: int = 5):\n",
        "        if index is None or len(corpus) == 0:\n",
        "            return []\n",
        "        qv = _embed_query(query, embedder_type, embedder_model, vectorizer)\n",
        "        if qv is None:\n",
        "            return []\n",
        "        scores, idxs = index.search(qv.astype(np.float32), top_k_local)\n",
        "        out = []\n",
        "        for s, i in zip(scores[0], idxs[0]):\n",
        "            if int(i) >= 0:\n",
        "                out.append((float(s), corpus[int(i)]))\n",
        "        return out\n",
        "\n",
        "    def local_sparse_search(query: str, top_k_local: int = 5):\n",
        "        if bm25 is None or len(corpus) == 0:\n",
        "            return []\n",
        "        scores = bm25.get_scores(tokenize(query))\n",
        "        top = np.argsort(scores)[::-1][:top_k_local]\n",
        "        return [(float(scores[i]), corpus[int(i)]) for i in top]\n",
        "\n",
        "    if method == \"dense\":\n",
        "        res = local_dense_search(query_text, top_k_local=max(10, top_k))\n",
        "        items = [it for _, it in res]\n",
        "    elif method == \"sparse\":\n",
        "        res = local_sparse_search(query_text, top_k_local=max(10, top_k))\n",
        "        items = [it for _, it in res]\n",
        "    else:\n",
        "        d = local_dense_search(query_text, top_k_local=max(10, top_k))\n",
        "        s = local_sparse_search(query_text, top_k_local=max(10, top_k))\n",
        "        res = hybrid_fuse(d, s, alpha=alpha, top_k=max(10, top_k))\n",
        "        items = [it for _, it in res]\n",
        "\n",
        "    if use_rerank:\n",
        "        items = rerank(query_text, items, lambda it: it.text, top_k=top_k)\n",
        "    else:\n",
        "        items = items[:top_k]\n",
        "\n",
        "    evidence_pack = [\n",
        "        {\"type\": \"text\", \"cite\": f\"[{it.chunk_id}]\", \"content\": it.text[:800]}\n",
        "        for it in items\n",
        "    ]\n",
        "\n",
        "    prompt_text = rag_prompt(prompt, evidence_pack)\n",
        "    answer = generate_answer(prompt, evidence_pack, max_sentences=4)\n",
        "\n",
        "    return {\n",
        "        \"search\": search_query,\n",
        "        \"evidence_pack\": evidence_pack,\n",
        "        \"answer\": answer,\n",
        "        \"prompt\": prompt_text,\n",
        "    }\n",
        "\n",
        "\n",
        "def demo_one(qobj, chunking=\"record\", method=\"hybrid\",\n",
        "             top_k_text=4, alpha=0.5, use_rerank=True):\n",
        "    return retrieve_from_api(\n",
        "        prompt=qobj[\"question\"],\n",
        "        keywords=qobj.get(\"keywords\"),\n",
        "        chunking=chunking,\n",
        "        method=method,\n",
        "        top_k=top_k_text,\n",
        "        alpha=alpha,\n",
        "        use_rerank=use_rerank,\n",
        "    )\n",
        "\n",
        "\n",
        "for q in QUERIES:\n",
        "    result = demo_one(q)\n",
        "    ep = result[\"evidence_pack\"]\n",
        "    ans = result[\"answer\"]\n",
        "    print(\"\\n=== \", q[\"id\"], \" ===\")\n",
        "    print(\"Q:\", q[\"question\"])\n",
        "    print(\"Search:\", result[\"search\"])\n",
        "    print(\"Must-cite:\", q.get(\"must_cite\", []))\n",
        "    print(\"Top evidence citations:\", [e[\"cite\"] for e in ep])\n",
        "    print(\"Answer:\\n\", ans)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5af324fc",
      "metadata": {
        "id": "5af324fc"
      },
      "source": [
        "## 11) Week 3 acceptance tests (CS 5588)\n",
        "Fill in after running your demo:\n",
        "- Does the evidence pack include the must-cite items for Q1/Q2?\n",
        "- Does Q3 properly refuse with “Not enough evidence…”?\n",
        "- Is the output understandable to your target user?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "03b64e9f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "03b64e9f",
        "outputId": "740d42b7-45c0-492e-e146-198477ffce74"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'qid': 'Q1',\n",
              "  'must_cite_expected': 'doc2.pdf + fig5.jpg + fig6.jpg',\n",
              "  'pass_fail': 'PASS',\n",
              "  'notes': 'Evidence pack includes doc2.pdf pages plus both required figures (fig5.jpg, fig6.jpg). Answer is grounded and cited.'},\n",
              " {'qid': 'Q2',\n",
              "  'must_cite_expected': 'doc1.pdf + fig2.jpg + fig3.jpg',\n",
              "  'pass_fail': 'PASS',\n",
              "  'notes': 'Query wording/keywords explicitly target Figure 2 (Urgent threats) and Figure 3 (at least 35,900 deaths), so evidence pack includes both must-cite figures and doc1 context.'},\n",
              " {'qid': 'Q3',\n",
              "  'must_cite_expected': '(none) — should refuse',\n",
              "  'pass_fail': 'PASS',\n",
              "  'notes': \"System refuses exactly: 'Not enough evidence in the retrieved context.'\"}]"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ACCEPTANCE_CHECKLIST = [\n",
        "    {\n",
        "        \"qid\": \"Q1\",\n",
        "        \"must_cite_expected\": \"drug_interactions\",\n",
        "        \"pass_fail\": \"PENDING\",\n",
        "        \"notes\": \"Evidence pack should include drug_interactions content for caffeine-related labels.\"\n",
        "    },\n",
        "    {\n",
        "        \"qid\": \"Q2\",\n",
        "        \"must_cite_expected\": \"dosage_and_administration + warnings\",\n",
        "        \"pass_fail\": \"PENDING\",\n",
        "        \"notes\": \"Evidence pack should include dosage guidance and warnings for acetaminophen labels.\"\n",
        "    },\n",
        "    {\n",
        "        \"qid\": \"Q3\",\n",
        "        \"must_cite_expected\": \"(none) — should refuse\",\n",
        "        \"pass_fail\": \"PENDING\",\n",
        "        \"notes\": \"System should refuse exactly: 'Not enough evidence in the retrieved context.'\"\n",
        "    },\n",
        "]\n",
        "ACCEPTANCE_CHECKLIST"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f55742c0",
      "metadata": {
        "id": "f55742c0"
      },
      "source": [
        "## 11.5 Team work items (project enhancement)\n",
        "\n",
        "Use this hands-on to **advance your semester project**. Each team member should “own” at least one deliverable below.\n",
        "\n",
        "**Product Lead (Applicability)**\n",
        "- Update your project **persona + workflow** so the openFDA RAG module is a *core feature*, not an add-on.\n",
        "- Write 3 stakeholder tasks that map to your product’s real decision points (2 require label evidence, 1 must refuse).\n",
        "\n",
        "**Systems Lead (Integration)**\n",
        "- Replace the toy query with your **project-domain openFDA queries**.\n",
        "- Add **metadata fields** that matter to your domain (e.g., `openfda.product_type`, `openfda.brand_name`, `application_number`).\n",
        "- Implement a clean **`retrieve_from_api()` helper** your final demo can reuse.\n",
        "\n",
        "**Evaluation & Risk Lead (Shipping readiness)**\n",
        "- Build a tiny evaluation table: *Task × Method × P@5 × R@10 × Faithfulness*.\n",
        "- Add one real failure scenario + mitigation UX (warnings, “show evidence” first, or human-in-the-loop flag).\n",
        "- Draft the “If we shipped this” plan: data refresh, monitoring, and governance rule.\n",
        "\n",
        "**Bonus (Optional)**\n",
        "- Add a minimal UI (Gradio/Streamlit) that shows: question → evidence pack → answer with citations.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7eb6e514",
      "metadata": {
        "id": "7eb6e514"
      },
      "source": [
        "## 12) Week 3 deliverables (CS 5588)\n",
        "- Product Brief completed (persona, problem, value, success metrics)\n",
        "- Demo run for Q1–Q3 with citations (screenshots encouraged)\n",
        "- 1 failure case + mitigation plan (risk + fix)\n",
        "- Repo link submitted in the survey\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "03d3dcff956046ac868c1ef42d23048e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_442e5f6527b34a4db3ec2eff92860fcc",
              "IPY_MODEL_9417759bb9cb466c82d964a11c6db6b0",
              "IPY_MODEL_583b0729373445649c53f84213137e5d"
            ],
            "layout": "IPY_MODEL_6f1bce9f804a4260862840538817b0ba"
          }
        },
        "098f9f5ea4a9439c90c3fac8c62a5a18": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "442e5f6527b34a4db3ec2eff92860fcc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_87a9b2e37b5945589898aee5adaf0f78",
            "placeholder": "​",
            "style": "IPY_MODEL_765e4e01ec7e442a93049d6f02f47c08",
            "value": "Loading weights: 100%"
          }
        },
        "49a291aa2957423aafabd41e0068e272": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_caf09549816840c7992d82d272b6b980",
              "IPY_MODEL_5cc1687838e94b09a054ce4fc518d96a",
              "IPY_MODEL_93ed0ba025bc4c7b99dfee1f077749fe"
            ],
            "layout": "IPY_MODEL_f4404319d4a247f29f2cb9ef0d0c1195"
          }
        },
        "583b0729373445649c53f84213137e5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c1dedb3a154c42089a808fa8e549c21d",
            "placeholder": "​",
            "style": "IPY_MODEL_af50bc305afe4112a77a1c1d1c8c8ca8",
            "value": " 105/105 [00:00&lt;00:00, 229.86it/s, Materializing param=classifier.weight]"
          }
        },
        "5cc1687838e94b09a054ce4fc518d96a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8d0ce16a5a7a4503beee4630cd773e2c",
            "max": 103,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a6119c94dc144cf19c9d3f25996cebbb",
            "value": 103
          }
        },
        "6f1bce9f804a4260862840538817b0ba": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "765e4e01ec7e442a93049d6f02f47c08": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7722d535af8a4cc9b21146d9d5c6011c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7d55010d2aca4e558c427b85b7ccc899": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "81e764d57070462b9bf518c07b6ed5c4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87a9b2e37b5945589898aee5adaf0f78": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d0ce16a5a7a4503beee4630cd773e2c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "93ed0ba025bc4c7b99dfee1f077749fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_81e764d57070462b9bf518c07b6ed5c4",
            "placeholder": "​",
            "style": "IPY_MODEL_7d55010d2aca4e558c427b85b7ccc899",
            "value": " 103/103 [00:00&lt;00:00, 252.34it/s, Materializing param=pooler.dense.weight]"
          }
        },
        "9417759bb9cb466c82d964a11c6db6b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c2d2f32bcd424442b3f0a3acae967056",
            "max": 105,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_afef67ebe3334645a48f3f38dc12f421",
            "value": 105
          }
        },
        "a6119c94dc144cf19c9d3f25996cebbb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "af50bc305afe4112a77a1c1d1c8c8ca8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "afef67ebe3334645a48f3f38dc12f421": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c1dedb3a154c42089a808fa8e549c21d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c2d2f32bcd424442b3f0a3acae967056": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "caf09549816840c7992d82d272b6b980": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_098f9f5ea4a9439c90c3fac8c62a5a18",
            "placeholder": "​",
            "style": "IPY_MODEL_7722d535af8a4cc9b21146d9d5c6011c",
            "value": "Loading weights: 100%"
          }
        },
        "f4404319d4a247f29f2cb9ef0d0c1195": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
